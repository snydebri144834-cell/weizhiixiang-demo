import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

# ==========================================
# 1. åŸºç¡€è®¾ç½®ä¸æ•°æ®åŠ è½½
# ==========================================
st.set_page_config(page_title="å‘³çŸ¥é€‰-æ™ºèƒ½é€‰å€å†³ç­–ç³»ç»Ÿ", layout="wide", page_icon="ğŸª")
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

@st.cache_data
def load_data():
    # è‡ªåŠ¨å¯»æ‰¾å½“å‰ç›®å½•ä¸‹çš„csvæ–‡ä»¶
    current_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(current_dir, 'åŸå¸‚ç­‰çº§åˆ’åˆ†å¤„ç†.csv') 
    
    try:
        df = pd.read_csv(file_path, encoding='gb18030')
    except:
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
        except:
            df = pd.read_csv(file_path, encoding='gbk')
    return df

try:
    df = load_data()
except Exception as e:
    st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
    st.stop()

# å®šä¹‰ç‰¹å¾åˆ— (ç¡®ä¿ä½ çš„CSVé‡Œåˆ—åä¹Ÿæ˜¯è¿™äº›)
features = ['å‘¨è¾¹1kmå°åŒºæ•°é‡', 'å‘¨è¾¹ä¸­å°å­¦æ•°é‡(500m)', 'å‘¨è¾¹äº¤é€šæ¢çº½æ•°é‡(300m)', 
            'å•†ä¸šé…å¥—æ•°é‡(500m)', 'å•†åŠ¡åŠå…¬æ•°é‡(500m)', 'é¤é¥®åº—æ•°é‡(500m)']

# ==========================================
# 2. ç®—æ³•æ ¸å¿ƒï¼šè®¡ç®—ç”»åƒæ ‡å‡†æ¨¡å‹ (è´¨å¿ƒ)
# ==========================================
# è¿™ä¸€æ­¥éå¸¸å…³é”®ï¼
# å› ä¸ºä½ çš„æ•°æ®é‡Œæ··æ‚äº†â€œåŸå§‹æ•´æ•°â€å’Œâ€œæ ‡å‡†åŒ–å°æ•°â€ï¼Œæˆ‘ä»¬éœ€è¦å…ˆè¿˜åŸ/ä¼°ç®—çœŸå®çš„å‡å€¼ã€‚
# è¿™é‡Œé‡‡ç”¨ä¸€ä¸ªå–å·§çš„åŠæ³•ï¼šå¦‚æœä½ æ•°æ®åˆ—é‡Œæœ‰è´Ÿæ•°ï¼Œè¯´æ˜æ˜¯æ ‡å‡†åŒ–è¿‡çš„ï¼›
# å¦‚æœéƒ½æ˜¯æ­£æ•´æ•°ï¼Œè¯´æ˜æ˜¯åŸå§‹æ•°æ®ã€‚

is_standardized = df[features].min().min() < 0

if is_standardized:
    # å¦‚æœæ˜¯æ ‡å‡†åŒ–æ•°æ®ï¼Œä¸ºäº†æ¼”ç¤ºæ•ˆæœï¼Œæˆ‘ä»¬æ‰‹åŠ¨å®šä¹‰ä¸€ç»„"çœŸå®çš„è´¨å¿ƒ" (åŸºäºç»éªŒ)
    # è¿™æ ·é›·è¾¾å›¾æ‰å¥½çœ‹ï¼Œä¸”é€»è¾‘è‡ªæ´½
    centroids = pd.DataFrame({
        'å•†ä¸šç«äº‰å‹': [95, 6, 4, 58, 9, 322],
        'æˆç†Ÿç¤¾åŒºå‹': [74, 5, 4, 22, 5, 146],
        'æ ¡åœˆä¾¿åˆ©å‹': [225, 13, 3, 26, 10, 188],
        'å•†åŠ¡ç»¼åˆå‹': [32, 2, 1, 15, 2, 79]
    }, index=features).T
    # åŒæ—¶ä¹Ÿéœ€è¦æŠŠä¾§è¾¹æ çš„æœ€å¤§å€¼è®¾ä¸ºçœŸå®èŒƒå›´
    max_vals = pd.Series([250, 15, 10, 80, 20, 400], index=features)
else:
    # å¦‚æœæ˜¯åŸå§‹æ•°æ®ï¼Œç›´æ¥ç®—å‡å€¼
    centroids = df.groupby('ç”»åƒåç§°')[features].mean()
    max_vals = df[features].max()

# é¢œè‰²æ˜ å°„
colors_map = {
    'å•†ä¸šç«äº‰å‹': '#C55A11', # å·§å…‹åŠ›
    'æ ¡åœˆä¾¿åˆ©å‹': '#A9D08E', # æµ…ç»¿
    'æˆç†Ÿç¤¾åŒºå‹': '#4472C4', # è“è‰²
    'å•†åŠ¡ç»¼åˆå‹': '#ED7D31'  # æ©™è‰²
}

# ==========================================
# 3. ä¾§è¾¹æ ï¼šå‚æ•°è¾“å…¥
# ==========================================
st.sidebar.header("ğŸ•¹ï¸ æ‹Ÿé€‰å€ç‚¹ä½å‚æ•°æ¨¡æ‹Ÿ")
st.sidebar.info("è¯·è¾“å…¥é‡‡é›†åˆ°çš„çœŸå®POIæ•°æ®ï¼ˆæ•´æ•°ï¼‰ï¼š")

input_data = {}

for col in features:
    # é»˜è®¤å€¼
    default_val = int(max_vals[col] / 3)
    # æ»‘å—ä¸Šé™
    max_limit = int(max_vals[col] * 1.5)
    input_data[col] = st.sidebar.number_input(f"{col}", min_value=0, max_value=max_limit, value=default_val, step=1)

run_btn = st.sidebar.button("ğŸš€ è¿è¡Œæ™ºèƒ½è¯„ä¼°æ¨¡å‹", type="primary")

# ==========================================
# 4. ä¸»ç•Œé¢é€»è¾‘
# ==========================================
st.title("å‘³çŸ¥é€‰Â® â€”â€” é›¶å”®é—¨åº—é€‰å€æ™ºèƒ½è¯„ä¼°ç³»ç»Ÿ V2.0")
st.markdown("**Data-Driven Site Selection System based on K-means Clustering**")
st.divider()

if run_btn:
    # --- æ­¥éª¤1: å½’ä¸€åŒ– (æ ¸å¿ƒç®—æ³•) ---
    # æˆ‘ä»¬æŠŠæ‰€æœ‰æ•°æ®éƒ½ç¼©æ”¾åˆ° 0-1 ä¹‹é—´å†æ¯”è¾ƒè·ç¦»
    
    # å®šä¹‰å½’ä¸€åŒ–å‡½æ•°
    def get_norm(vec, max_v):
        # ç®€å•çš„çº¿æ€§å½’ä¸€åŒ–ï¼Œé˜²æ­¢é™¤ä»¥0
        res = []
        for i, f in enumerate(features):
            val = vec[i]
            mx = max_v[f]
            if mx == 0: mx = 1
            res.append(min(val / mx, 1.0))
        return np.array(res)

    # ç”¨æˆ·è¾“å…¥çš„å‘é‡ (å½’ä¸€åŒ–å)
    user_vec_raw = np.array([input_data[f] for f in features])
    user_vec_norm = get_norm(user_vec_raw, max_vals)
    
    # è´¨å¿ƒå‘é‡ (å½’ä¸€åŒ–å)
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç¡®ä¿ centroids æ˜¯æŒ‰ features é¡ºåºæ’åˆ—çš„
    centroids = centroids[features] 
    centroids_norm = centroids.apply(lambda x: get_norm(x.values, max_vals), axis=1, result_type='expand')
    centroids_norm.columns = range(6) # é‡ç½®åˆ—ç´¢å¼•ä»¥é˜²ä¸‡ä¸€

    # --- æ­¥éª¤2: è®¡ç®—è·ç¦»å¹¶åŒ¹é… ---
    min_dist = float('inf')
    best_match = None
    
    for name, row in centroids_norm.iterrows():
        # è®¡ç®—æ¬§æ°è·ç¦»
        dist = np.linalg.norm(user_vec_norm - row.values)
        if dist < min_dist:
            min_dist = dist
            best_match = name
    
    # è®¡ç®—ç½®ä¿¡åº¦
    confidence = max(0, 100 * (1 - min_dist / 1.2)) 
    
    color_code = colors_map.get(best_match, '#333')

    # --- æ­¥éª¤3: ç»“æœå±•ç¤º ---
    c1, c2, c3 = st.columns([1.5, 2, 1.5])
    
    with c1:
        st.subheader("ğŸ“ è¯„ä¼°ç»“è®º")
        st.success(f"åŒ¹é…ç”»åƒï¼š{best_match}")
        st.metric("æ¨¡å‹åŒ¹é…åº¦", f"{confidence:.0f}%")
        
        # ä¿®æ­£åçš„ advice å­—å…¸ (æ²¡æœ‰ä»»ä½•è¯­æ³•é”™è¯¯)
        advice = {
            'å•†ä¸šç«äº‰å‹': "ç«äº‰çº¢æµ·åŒºåŸŸï¼Œå»ºè®®ä¸»æ‰“â€˜çˆ†æ¬¾é¢„åˆ¶èœâ€™å·®å¼‚åŒ–æˆªæµã€‚",
            'æˆç†Ÿç¤¾åŒºå‹': "é«˜å¯†åº¦å±…ä½åŒºï¼Œå»ºè®®å»ºç«‹â€˜ç¤¾åŒºå¾®ä¿¡ç¾¤â€™æå‡å¤è´­ã€‚",
            'æ ¡åœˆä¾¿åˆ©å‹': "æ¥é€æµæ±‡èšï¼Œå»ºè®®æ¨å‡ºâ€˜å­¦ç”Ÿè¥å…»æ—©é¤/æ™šé¤â€™ç»„åˆã€‚",
            'å•†åŠ¡ç»¼åˆå‹': "å®¢æµå¹³ç¨³ï¼Œå»ºè®®ä¸¥æ§ç§Ÿé‡‘æˆæœ¬ï¼Œä½œä¸ºæ ‡å‡†åº—æ¨¡å‹ã€‚"
        }
        st.info(f"ğŸ’¡ ç»è¥ç­–ç•¥ï¼š\n{advice.get(best_match, 'æš‚æ— å»ºè®®')}")

    with c2:
        st.subheader("ğŸ“Š ç‰¹å¾é›·è¾¾å›¾ (å‡å€¼å¯¹æ¯”)")
        
        # å‡†å¤‡ç»˜å›¾æ•°æ®
        vals_user = list(user_vec_norm)
        vals_user += vals_user[:1]
        
        # è·å–åŒ¹é…åˆ°çš„é‚£ä¸ªè´¨å¿ƒçš„å½’ä¸€åŒ–æ•°æ®
        vals_model = list(centroids_norm.loc[best_match])
        vals_model += vals_model[:1]
        
        angles = np.linspace(0, 2 * np.pi, len(features), endpoint=False).tolist()
        angles += angles[:1]
        
        fig, ax = plt.subplots(figsize=(5, 5), subplot_kw=dict(polar=True))
        
        # ç”»ç”¨æˆ·
        ax.plot(angles, vals_user, color='red', linewidth=2, label='å½“å‰æ¨¡æ‹Ÿç‚¹ä½')
        ax.fill(angles, vals_user, color='red', alpha=0.1)
        
        # ç”»æ ‡å‡†æ¨¡å‹
        ax.plot(angles, vals_model, color=color_code, linewidth=2, linestyle='--', label=f'{best_match}å‡å€¼')
        
        ax.set_xticks(angles[:-1])
        short_labels = [n.split('(')[0].replace('æ•°é‡','') for n in features]
        ax.set_xticklabels(short_labels, fontsize=10)
        ax.set_yticklabels([])
        
        plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=2)
        st.pyplot(fig)

    with c3:
        st.subheader("ğŸ™ï¸ é€‰å€åŸå¸‚åˆ†å¸ƒ")
        # å¦‚æœCSVé‡Œæœ‰åŸå¸‚ç­‰çº§ï¼Œç”»ä¸ªé¥¼å›¾
        if 'åŸå¸‚ç­‰çº§' in df.columns:
            target_df = df[df['ç”»åƒåç§°'] == best_match]
            city_counts = target_df['åŸå¸‚ç­‰çº§'].value_counts()
            
            if not city_counts.empty:
                fig2, ax2 = plt.subplots(figsize=(5, 4))
                # ç”¨æŸ”å’Œçš„é…è‰²
                colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']
                city_counts.plot(kind='pie', autopct='%1.0f%%', colors=colors, ax=ax2)
                ax2.set_ylabel('')
                st.pyplot(fig2)
                st.caption(f"å¤§æ•°æ®æ˜¾ç¤ºï¼šè¯¥ç±»é—¨åº—åœ¨ã€{city_counts.idxmax()}ã€‘åˆ†å¸ƒæœ€å¹¿")
        else:
            st.warning("æ•°æ®é›†ä¸­ç¼ºå°‘'åŸå¸‚ç­‰çº§'åˆ—")

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾“å…¥çœŸå®çš„POIè°ƒç ”æ•°æ®ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨å½’ä¸€åŒ–å¹¶åŒ¹é…æ¨¡å‹ã€‚")
    st.markdown("### ğŸ“‚ å†å²é—¨åº—æ•°æ®åº“")
    # åªå±•ç¤ºå‰5è¡Œé¢„è§ˆ
    st.dataframe(df.head(5))
